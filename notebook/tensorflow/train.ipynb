{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2\"\n",
    "# os.environ['LD_PRELOAD'] = \"/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4\"\n",
    "sys.path.append('/root/code')\n",
    "\n",
    "import h5py as h5\n",
    "from definitions import LOG_DIR, WEIGHT_DIR, DATASET_DIR\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import time\n",
    "import datetime\n",
    "import numpy\n",
    "from models.Layers import STSA\n",
    "from models.SCNN18 import SCNN18\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import utils.dataset as dataset\n",
    "import logging\n",
    "from logging import handlers\n",
    "\n",
    "\n",
    "LOG = logging.getLogger('root')\n",
    "\n",
    "def initLog(debug=False):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(levelname)s %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M',\n",
    "        handlers=[logging.StreamHandler(), handlers.RotatingFileHandler('SCNN18_Attention.log', \"w\", 1024 * 1024 * 100, 3, \"utf-8\")]\n",
    "    )\n",
    "    LOG.setLevel(logging.DEBUG if debug else logging.INFO)\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "\n",
    "initLog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer, lr):\n",
    "    optimizer = optimizer.lower()\n",
    "    if optimizer == 'adadelta':\n",
    "        return tf.optimizers.Adadelta() if lr == 0 else tf.optimizers.Adadelta(learning_rate=lr)\n",
    "    elif optimizer == 'adagrad':\n",
    "        return tf.optimizers.Adagrad() if lr == 0 else tf.optimizers.Adagrad(learning_rate=lr)\n",
    "    elif optimizer == 'adam':\n",
    "        return tf.optimizers.Adam() if lr == 0 else tf.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'adamax':\n",
    "        return tf.optimizers.Adamax() if lr == 0 else tf.optimizers.Adamax(learning_rate=lr)\n",
    "    elif optimizer == 'sgd':\n",
    "        return tf.optimizers.SGD() if lr == 0 else tf.optimizers.SGD(learning_rate=lr,momentum=0.9)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        return tf.optimizers.RMSprop() if lr == 0 else tf.optimizers.RMSprop(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-parameter\n",
    "lr = 1.0\n",
    "max_epochs = 160\n",
    "batch_size = 150\n",
    "input_height = 32000\n",
    "input_width = 1\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.load('./SCNN-Jamendo-train.h5')\n",
    "# train_ds = train_ds.take(100)\n",
    "dataset_length = [i for i, _ in enumerate(train_ds)][-1] + 1\n",
    "# train_ds = train_ds.take(int((dataset_length-1)/4))\n",
    "print(dataset_length)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "# .shuffle(\n",
    "    # dataset_length, reshuffle_each_iteration=False)\n",
    "\n",
    "val_ds = dataset.load('./SCNN-Jamendo-test.h5')\n",
    "# val_ds =val_ds.take(1)\n",
    "dataset_length = [i for i, _ in enumerate(val_ds)][-1] + 1\n",
    "# val_ds = val_ds.take(int((dataset_length-2)/2))\n",
    "print(dataset_length)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingStepLogger(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        LOG.info(f'End of Epoch {epoch + 1} - Loss: {logs[\"loss\"]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (input_height, input_width)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[f'/gpu:{i}' for i in range(3)])\n",
    "with strategy.scope():\n",
    "    model = SCNN18(input_shape, nb_classes).model()\n",
    "    optimizer = get_optimizer('adadelta', lr)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary(print_fn=LOG.info)\n",
    "\n",
    "training_step_logger = TrainingStepLogger()\n",
    "model.fit(train_ds, validation_data=val_ds,\n",
    "          epochs=max_epochs,\n",
    "          callbacks=[training_step_logger])\n",
    "\n",
    "model.save_weights(os.path.join(WEIGHT_DIR, f\"{str(datetime.date.today())}_SCNN18_training_1.h5\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
